{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cjsal\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cjsal\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\cjsal\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Collecting numpy>=1.19.5 (from scikit-learn)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.0 MB 2.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.4/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.2/11.0 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.2/11.0 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.0/11.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.1/11.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/15.8 MB 3.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.6/15.8 MB 4.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 4.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 4.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.6/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.7/15.8 MB 2.9 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 5.5/15.8 MB 3.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 6.3/15.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 8.1/15.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.2/15.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.1\n",
      "    Uninstalling scikit-learn-1.3.1:\n",
      "      Successfully uninstalled scikit-learn-1.3.1\n",
      "Successfully installed numpy-1.26.4 scikit-learn-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~.mpy'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\cjsal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Bloque 1: Instalación de las librerías necesarias\n",
    "\n",
    "# Si no tienes las librerías instaladas o necesitas actualizar, puedes usar lo siguiente:\n",
    "#!pip install --upgrade numpy\n",
    "#!pip install --upgrade pandas\n",
    "#!pip install --upgrade nltk\n",
    "#!pip install --upgrade openpyxl  \n",
    "#!pip install --upgrade scikit-learn  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\__init__.py:133\u001b[0m\n\u001b[0;32m    125\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mPopen \u001b[38;5;241m=\u001b[39m _fake_Popen\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# TOP-LEVEL MODULES\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Import top-level functionality into top-level namespace\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollocations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator, memoize\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatstruct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\collocations.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_itertools\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# these two unused imports are referenced in collocations.doctest\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     BigramAssocMeasures,\n\u001b[0;32m     38\u001b[0m     ContingencyMeasures,\n\u001b[0;32m     39\u001b[0m     QuadgramAssocMeasures,\n\u001b[0;32m     40\u001b[0m     TrigramAssocMeasures,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspearman\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ranks_from_scores, spearman_correlation\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\metrics\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magreement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotationTask\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m align\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massociation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     BigramAssocMeasures,\n\u001b[0;32m     20\u001b[0m     ContingencyMeasures,\n\u001b[0;32m     21\u001b[0m     NgramAssocMeasures,\n\u001b[0;32m     22\u001b[0m     QuadgramAssocMeasures,\n\u001b[0;32m     23\u001b[0m     TrigramAssocMeasures,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfusionmatrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrix\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     binary_distance,\n\u001b[0;32m     28\u001b[0m     custom_distance,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     presence,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\metrics\\association.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m _SMALL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-20\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fisher_exact\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfisher_exact\u001b[39m(\u001b[38;5;241m*\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs):\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper, _get_nan,\n\u001b[0;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\__init__.py:110\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cjsal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\_kdtree.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[1;32m_ckdtree.pyx:1\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Bloque 2: Importar librerías necesarias y cargar el dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Descargar recursos de NLTK necesarios (stopwords y tokenizer)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar el archivo de datos (debes tener 'Corpus-Agro.xlsx' en tu directorio)\n",
    "df = pd.read_excel('Corpus-Agro.xlsx')\n",
    "\n",
    "# Ver las primeras filas del dataframe para asegurarnos de que se ha cargado correctamente\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 3: Limpiar los resúmenes del dataset utilizando un análisis léxico\n",
    "\n",
    "# Definir el conjunto de stopwords en inglés\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Definir la función para limpiar los resúmenes (análisis léxico)\n",
    "def limpiar_texto_lexico(texto):\n",
    "    if isinstance(texto, float):  # Comprobar si el texto es un número o NaN\n",
    "        return \"\"\n",
    "    \n",
    "    # Convertir el texto a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Tokenizar el texto (separar palabras)\n",
    "    palabras = word_tokenize(texto)\n",
    "    \n",
    "    # Filtrar stopwords y puntuación\n",
    "    palabras_limpias = [word for word in palabras if word not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    return \" \".join(palabras_limpias)\n",
    "\n",
    "# Aplicar la función de limpieza a todos los resúmenes\n",
    "df['Resumen_Limpio'] = df['Resumen'].apply(limpiar_texto_lexico)\n",
    "\n",
    "# Mostrar algunos resultados limpios\n",
    "df[['Resumen', 'Resumen_Limpio']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 4: Entrenar un modelo Word2Vec utilizando los resúmenes limpios\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenizar todos los resúmenes limpios para entrenar Word2Vec\n",
    "resumenes_tokenizados = [word_tokenize(texto) for texto in df['Resumen_Limpio']]\n",
    "\n",
    "# Entrenar el modelo Word2Vec\n",
    "modelo_word2vec = Word2Vec(resumenes_tokenizados, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Guardar el modelo entrenado (opcional, si quieres reutilizarlo más tarde)\n",
    "modelo_word2vec.save(\"modelo_word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 5: Solicitar una consulta al usuario y procesarla\n",
    "\n",
    "# Pedir al usuario que ingrese su consulta\n",
    "consulta_usuario = input(\"Por favor, ingresa tu consulta sobre agricultura: \").lower()\n",
    "\n",
    "# Tokenizar la consulta del usuario\n",
    "tokens_consulta = word_tokenize(consulta_usuario)\n",
    "\n",
    "# Generar un vector promedio para la consulta\n",
    "vector_consulta = np.mean([modelo_word2vec.wv[token] for token in tokens_consulta if token in modelo_word2vec.wv], axis=0)\n",
    "\n",
    "# Si no se encuentran palabras en el modelo, manejar el caso\n",
    "if np.isnan(vector_consulta).any():\n",
    "    print(\"La consulta no contiene palabras reconocidas por el modelo.\")\n",
    "else:\n",
    "    print(\"Consulta vectorizada correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 6: Calcular la similitud coseno entre la consulta y los resúmenes\n",
    "\n",
    "# Vectorizar cada resumen utilizando el modelo Word2Vec (promediando los vectores de palabras)\n",
    "def vectorizar_resumen(texto):\n",
    "    tokens = word_tokenize(texto)\n",
    "    vector = np.mean([modelo_word2vec.wv[token] for token in tokens if token in modelo_word2vec.wv], axis=0)\n",
    "    return vector\n",
    "\n",
    "# Aplicar la vectorización a todos los resúmenes limpios\n",
    "df['Vector_Resumen'] = df['Resumen_Limpio'].apply(vectorizar_resumen)\n",
    "\n",
    "# Calcular la similitud coseno entre la consulta y los resúmenes\n",
    "df['Similitud'] = df['Vector_Resumen'].apply(lambda x: cosine_similarity([x], [vector_consulta])[0][0])\n",
    "\n",
    "# Ordenar los resúmenes por similitud (de mayor a menor)\n",
    "df_resultados = df[['URL del Documento', 'Resumen', 'Similitud']].sort_values(by='Similitud', ascending=False)\n",
    "\n",
    "# Mostrar los primeros n resultados más relevantes\n",
    "n = 5  # Puedes cambiar el número de resultados a mostrar\n",
    "print(df_resultados.head(n))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
